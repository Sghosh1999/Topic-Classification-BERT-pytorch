{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1226200,"sourceType":"datasetVersion","datasetId":701505}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        continue\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-12T09:02:00.478614Z","iopub.execute_input":"2024-07-12T09:02:00.478876Z","iopub.status.idle":"2024-07-12T09:02:01.559354Z","shell.execute_reply.started":"2024-07-12T09:02:00.478852Z","shell.execute_reply":"2024-07-12T09:02:01.558358Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Dataset : [https://www.kaggle.com/datasets/jensenbaxter/10dataset-text-document-classification/data]","metadata":{}},{"cell_type":"markdown","source":"## Importing Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.preprocessing import LabelEncoder\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-07-12T09:02:04.424466Z","iopub.execute_input":"2024-07-12T09:02:04.425518Z","iopub.status.idle":"2024-07-12T09:02:09.785516Z","shell.execute_reply.started":"2024-07-12T09:02:04.425469Z","shell.execute_reply":"2024-07-12T09:02:09.784583Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"data = {'Content': [], 'Label': []}\nfor dirname, _, filenames in os.walk('/kaggle/input/10dataset-text-document-classification'):\n    for filename in filenames:\n        # Read the content of the file\n        file_path = os.path.join(dirname, filename)\n        with open(file_path, 'r', encoding='utf-8') as file:\n            content = file.read()\n\n        # Use directory name as the label\n        label = os.path.basename(dirname)\n\n        # Append data to the dictionary\n        data['Content'].append(content)\n        data['Label'].append(label)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T09:02:28.448219Z","iopub.execute_input":"2024-07-12T09:02:28.449108Z","iopub.status.idle":"2024-07-12T09:02:30.779688Z","shell.execute_reply.started":"2024-07-12T09:02:28.449076Z","shell.execute_reply":"2024-07-12T09:02:30.778714Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Create a DataFrame\ndf = pd.DataFrame(data)\n\n# Display the DataFrame\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T09:51:15.527664Z","iopub.execute_input":"2024-07-12T09:51:15.528057Z","iopub.status.idle":"2024-07-12T09:51:15.536773Z","shell.execute_reply.started":"2024-07-12T09:51:15.528029Z","shell.execute_reply":"2024-07-12T09:51:15.535659Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"                                               Content     Label\n0    Archive-name: space/intro\\nLast-modified: $Dat...     space\n1    shag@aero.org (Rob Unverzagt) writes:\\n>In art...     space\n2    Does anyone know how to size cold gas roll con...     space\n3    nanderso@Endor.sim.es.com (Norman Anderson) wr...     space\n4    Here are some recent observations taken by the...     space\n..                                                 ...       ...\n995  US interest rate rise expected\\n\\nUS interest ...  business\n996  House prices drop as sales slow\\n\\nHouse price...  business\n997  UK economy facing 'major risks'\\n\\nThe UK manu...  business\n998  Industrial revival hope for Japan\\n\\nJapanese ...  business\n999  Peugeot deal boosts Mitsubishi\\n\\nStruggling J...  business\n\n[1000 rows x 2 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"unique_labels = df['Label'].unique()\nprint(\"Unique Labels:\")\nprint(unique_labels)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T09:51:16.851625Z","iopub.execute_input":"2024-07-12T09:51:16.852575Z","iopub.status.idle":"2024-07-12T09:51:16.858726Z","shell.execute_reply.started":"2024-07-12T09:51:16.852532Z","shell.execute_reply":"2024-07-12T09:51:16.857551Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Unique Labels:\n['space' 'politics' 'sport' 'technologie' 'historical' 'medical'\n 'graphics' 'entertainment' 'food' 'business']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Label Encoder","metadata":{}},{"cell_type":"code","source":"label_encoder = LabelEncoder()\ndf['Label'] = label_encoder.fit_transform(df['Label'])","metadata":{"execution":{"iopub.status.busy":"2024-07-12T09:51:21.374696Z","iopub.execute_input":"2024-07-12T09:51:21.375041Z","iopub.status.idle":"2024-07-12T09:51:21.380748Z","shell.execute_reply.started":"2024-07-12T09:51:21.375016Z","shell.execute_reply":"2024-07-12T09:51:21.379711Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"texts = df['Content'].tolist()\nlabels = df['Label'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-07-12T09:51:31.617714Z","iopub.execute_input":"2024-07-12T09:51:31.618109Z","iopub.status.idle":"2024-07-12T09:51:31.623087Z","shell.execute_reply.started":"2024-07-12T09:51:31.618076Z","shell.execute_reply":"2024-07-12T09:51:31.622189Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.model_selection import train_test_split\n\n# Check if a GPU is available and set the device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nclass TextClassificationDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n        encoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n        return {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(), 'label': torch.tensor(label)}\n\nclass BERTClassifier(nn.Module):\n    def __init__(self, bert_model_name, num_classes):\n        super(BERTClassifier, self).__init__()\n        self.bert = BertModel.from_pretrained(bert_model_name)\n        self.dropout = nn.Dropout(0.1)\n        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.pooler_output\n        x = self.dropout(pooled_output)\n        logits = self.fc(x)\n        return logits\n\ndef train(model, data_loader, optimizer, scheduler, device):\n    model.train()\n    for batch in data_loader:\n        optimizer.zero_grad()\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        loss = nn.CrossEntropyLoss()(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\ndef evaluate(model, data_loader, device):\n    model.eval()\n    predictions = []\n    actual_labels = []\n    with torch.no_grad():\n        for batch in data_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            _, preds = torch.max(outputs, dim=1)\n            predictions.extend(preds.cpu().tolist())\n            actual_labels.extend(labels.cpu().tolist())\n    return accuracy_score(actual_labels, predictions), classification_report(actual_labels, predictions)\n\ndef predict_class(text, model, tokenizer, max_length=128, device='cpu'):\n    model.eval()\n    encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n    input_ids = encoding['input_ids'].to(device)\n    attention_mask = encoding['attention_mask'].to(device)\n    with torch.no_grad():\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        _, preds = torch.max(outputs, dim=1)\n    return preds.item()","metadata":{"execution":{"iopub.status.busy":"2024-07-12T09:36:18.251260Z","iopub.execute_input":"2024-07-12T09:36:18.252134Z","iopub.status.idle":"2024-07-12T09:36:18.271994Z","shell.execute_reply.started":"2024-07-12T09:36:18.252098Z","shell.execute_reply":"2024-07-12T09:36:18.271070Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"## Fine Tuning Model Parameter","metadata":{}},{"cell_type":"code","source":"bert_model_name = 'bert-base-uncased'\nnum_classes = 10\nmax_length = 128\nbatch_size = 16\nnum_epochs = 4\nlearning_rate = 2e-5\n\n# Define the model and move it to the device\nmodel = BERTClassifier(bert_model_name, num_classes).to(device)\n\n# Use stratify to ensure all labels get to train and test\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    texts, labels, test_size=0.2, random_state=42, stratify=labels)\n\ntokenizer = BertTokenizer.from_pretrained(bert_model_name)\ntrain_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer, max_length)\nval_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n\noptimizer = AdamW(model.parameters(), lr=learning_rate)\ntotal_steps = len(train_dataloader) * num_epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T09:36:45.197130Z","iopub.execute_input":"2024-07-12T09:36:45.197590Z","iopub.status.idle":"2024-07-12T09:36:45.879756Z","shell.execute_reply.started":"2024-07-12T09:36:45.197545Z","shell.execute_reply":"2024-07-12T09:36:45.878782Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Train The Model","metadata":{}},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n    train(model, train_dataloader, optimizer, scheduler, device)\n    accuracy, report = evaluate(model, val_dataloader, device)\n    print(f\"Validation Accuracy: {accuracy:.4f}\")\n    print(report)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T09:37:02.555027Z","iopub.execute_input":"2024-07-12T09:37:02.555934Z","iopub.status.idle":"2024-07-12T09:38:48.670113Z","shell.execute_reply.started":"2024-07-12T09:37:02.555899Z","shell.execute_reply":"2024-07-12T09:38:48.669164Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Epoch 1/4\nValidation Accuracy: 0.7600\n              precision    recall  f1-score   support\n\n           0       0.34      0.90      0.49        20\n           1       1.00      0.80      0.89        20\n           2       1.00      0.95      0.97        20\n           3       0.89      0.80      0.84        20\n           4       0.94      0.75      0.83        20\n           5       0.80      1.00      0.89        20\n           6       1.00      0.25      0.40        20\n           7       1.00      0.25      0.40        20\n           8       1.00      1.00      1.00        20\n           9       0.78      0.90      0.84        20\n\n    accuracy                           0.76       200\n   macro avg       0.87      0.76      0.76       200\nweighted avg       0.87      0.76      0.76       200\n\nEpoch 2/4\nValidation Accuracy: 0.9350\n              precision    recall  f1-score   support\n\n           0       0.94      0.75      0.83        20\n           1       1.00      1.00      1.00        20\n           2       0.95      1.00      0.98        20\n           3       0.90      0.90      0.90        20\n           4       0.95      1.00      0.98        20\n           5       0.95      1.00      0.98        20\n           6       0.83      0.95      0.88        20\n           7       1.00      0.85      0.92        20\n           8       1.00      1.00      1.00        20\n           9       0.86      0.90      0.88        20\n\n    accuracy                           0.94       200\n   macro avg       0.94      0.93      0.93       200\nweighted avg       0.94      0.94      0.93       200\n\nEpoch 3/4\nValidation Accuracy: 0.9500\n              precision    recall  f1-score   support\n\n           0       0.94      0.75      0.83        20\n           1       1.00      1.00      1.00        20\n           2       0.95      1.00      0.98        20\n           3       0.91      1.00      0.95        20\n           4       0.95      1.00      0.98        20\n           5       0.95      1.00      0.98        20\n           6       0.86      0.95      0.90        20\n           7       1.00      0.85      0.92        20\n           8       1.00      1.00      1.00        20\n           9       0.95      0.95      0.95        20\n\n    accuracy                           0.95       200\n   macro avg       0.95      0.95      0.95       200\nweighted avg       0.95      0.95      0.95       200\n\nEpoch 4/4\nValidation Accuracy: 0.9650\n              precision    recall  f1-score   support\n\n           0       0.94      0.80      0.86        20\n           1       0.95      1.00      0.98        20\n           2       1.00      1.00      1.00        20\n           3       1.00      0.95      0.97        20\n           4       1.00      1.00      1.00        20\n           5       0.95      1.00      0.98        20\n           6       0.87      1.00      0.93        20\n           7       0.95      0.95      0.95        20\n           8       1.00      1.00      1.00        20\n           9       1.00      0.95      0.97        20\n\n    accuracy                           0.96       200\n   macro avg       0.97      0.96      0.96       200\nweighted avg       0.97      0.96      0.96       200\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Making the Prediction","metadata":{}},{"cell_type":"code","source":"import torch\n\n# Ensure that the model is on the GPU\nmodel.to(device)\n\ndef predict_class(text, model, tokenizer, max_length=128, device='cpu'):\n    model.eval()\n    encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n    input_ids = encoding['input_ids'].to(device)\n    attention_mask = encoding['attention_mask'].to(device)\n    with torch.no_grad():\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        _, preds = torch.max(outputs, dim=1)\n    return preds.item()\n\n# Test sentiment prediction\ntest_text = \"This recipe is coming from my mother and originally use potato instead\"\nClass = predict_class(test_text, model, tokenizer, device=device)\nprint(f\"Predicted sentiment: {Class}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-12T09:51:38.909150Z","iopub.execute_input":"2024-07-12T09:51:38.909574Z","iopub.status.idle":"2024-07-12T09:51:38.937567Z","shell.execute_reply.started":"2024-07-12T09:51:38.909539Z","shell.execute_reply":"2024-07-12T09:51:38.936713Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Predicted sentiment: 2\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"Predicted sentiment: {label_encoder.inverse_transform([Class])[0]}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-12T09:52:14.499885Z","iopub.execute_input":"2024-07-12T09:52:14.500523Z","iopub.status.idle":"2024-07-12T09:52:14.505974Z","shell.execute_reply.started":"2024-07-12T09:52:14.500492Z","shell.execute_reply":"2024-07-12T09:52:14.504831Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Predicted sentiment: food\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}